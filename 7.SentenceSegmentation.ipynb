{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Sentence Segmentation Basics"
      ],
      "metadata": {
        "id": "uVhEyW0XREJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# officaial documentation\n",
        "# https://spacy.io/usage/linguistic-features/#sbd"
      ],
      "metadata": {
        "id": "MW_zr23nROFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAJgkRASQP-m"
      },
      "outputs": [],
      "source": [
        "# Import spaCy\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the English language library\n",
        "nlp = spacy.load(name=\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "bLBzaI45QbKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = nlp(\"This is a sentence. This is second sentence. This is last sentence.\")"
      ],
      "metadata": {
        "id": "2jRXMW2MRzGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in document.sents:\n",
        "    print(sentence.text)\n",
        "\n",
        "# note that doc.sents is a generator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueZNPtnNSbWf",
        "outputId": "7437a91c-917b-41cb-b8df-fa1d405aa1d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a sentence.\n",
            "This is second sentence.\n",
            "This is last sentence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document.sents[0]\n",
        "# if you try to grab individual sentences then you will get an error\n",
        "# TypeError: 'generator' object is not subscriptable\n",
        "# because this generates the sentences instead of holding them in memory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "5c-ZmRkPSbTu",
        "outputId": "3be0cbfe-f04c-4abd-8dd2-b10ac7b27ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'generator' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b72795a316a5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# if you try to grab individual sentences then you will get an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# TypeError: 'generator' object is not subscriptable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# because this generates the sentences instead of holding them in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grab a token\n",
        "document[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1lM70GqSbPm",
        "outputId": "5642713e-d8b3-4cf3-88f0-a8c824e31598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "This"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can grab individual tokens because spacy knows the language library,\n",
        "# we can grab individual sentences with list\n",
        "list(document.sents)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNF4N9vrTUxW",
        "outputId": "d454c40e-e1bf-47da-b5d5-1a9055d95162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "This is a sentence."
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# these are the spacy's span objects not normal strings\n",
        "type(list(document.sents)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfC6diSrTUhu",
        "outputId": "9bbf26c1-72e0-4f4b-a15c-0f589e85fcf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.span.Span"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now put U.K. to see if it only breaks the sentence on dots or not\n",
        "documentTwo = nlp(\"This is a sentence. This is second U.K. sentence. This is last sentence.\")"
      ],
      "metadata": {
        "id": "kvJKtJRcUT_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in documentTwo.sents:\n",
        "    print(sentence.text)\n",
        "\n",
        "# even after putting U.K. inside the first string\n",
        "# spacy able to detect that it is not a indication of sentence ending"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glhnq87fUkBV",
        "outputId": "8621a675-b18b-46c1-df4a-9387ef169e5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a sentence.\n",
            "This is second U.K. sentence.\n",
            "This is last sentence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Adding Rules\n",
        "\n",
        "We can add our own rules for sentence segmentation, but they have to be added before the creation of doc object\n",
        "\n",
        "becauseas that is where parsing of segment start"
      ],
      "metadata": {
        "id": "K3VtCJeNTtUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentThree = nlp(\"This is a sentence; This is second sentence; This is last sentence.\")"
      ],
      "metadata": {
        "id": "5NT0lMGyUBE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in documentThree.sents:\n",
        "    print(sentence.text)\n",
        "\n",
        "# this will show the whole string as a single sentence\n",
        "# cause by default spacy can not determine ; as a sentence ending properties"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1d3xV5QTs_u",
        "outputId": "9eb5ff09-d8cc-4a4b-9150-9efcf1fc6b4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a sentence;\n",
            "This is second sentence;\n",
            "This is last sentence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now, let's set custom rules\n",
        "# first import language from spacy\n",
        "from spacy.language import Language"
      ],
      "metadata": {
        "id": "oSGA8UHsXT0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now define custom rule function\n",
        "\n",
        "@Language.component(\"setCustomBoundaries\")\n",
        "def setCustomBoundaries(document):\n",
        "    for token in document[:-1]:   # we are going through every token except the last one\n",
        "      if token.text == ';':    # here we are adding a new Segmentation rule\n",
        "        # is_sent_start is the property of specific index\n",
        "        # which indicates this is sentence start or not\n",
        "        document[token.i+1].is_sent_start = True\n",
        "    return document\n",
        "\n",
        "# after the semicolan, the next token is start of new sentence\n",
        "\n",
        "# we are passing all the tokens through for loop except the last one because,\n",
        "# we are taking \"token.i+1\" is the start of new sentence\n",
        "# that is \"token.i+1\" includes last token in document(documentThree)"
      ],
      "metadata": {
        "id": "19Jl6L7bT3mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now add_pipe with custom rule function\n",
        "nlp.add_pipe(\"setCustomBoundaries\", before=\"parser\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "MkVtfGdtT3eV",
        "outputId": "f0ad52fe-ea81-471f-ab5c-e1c6d4414726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "[E007] 'setCustomBoundaries' already exists in pipeline. Existing names: ['tok2vec', 'tagger', 'setCustomBoundaries', 'parser', 'senter', 'attribute_ruler', 'lemmatizer', 'ner']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-fca0fc557e4e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# now add_pipe with custom rule function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"setCustomBoundaries\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[0;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfactory_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE007\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m         \u001b[0;31m# Overriding pipe name in the config is not supported and will be ignored.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"name\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: [E007] 'setCustomBoundaries' already exists in pipeline. Existing names: ['tok2vec', 'tagger', 'setCustomBoundaries', 'parser', 'senter', 'attribute_ruler', 'lemmatizer', 'ner']"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipe_names\n",
        "# new rule is added, that is 'set_custom_boundaries'\n",
        "# tagger, parser and ner are already there"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECsURy0hTsw9",
        "outputId": "f36565d7-25f7-480e-a54a-866218e7f65c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec',\n",
              " 'tagger',\n",
              " 'setCustomBoundaries',\n",
              " 'parser',\n",
              " 'attribute_ruler',\n",
              " 'lemmatizer',\n",
              " 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now with the new custom rule added\n",
        "# spacy can determine ; as a sentence ending properties\n",
        "\n",
        "# but for that we need to reinitialize the following again\n",
        "\n",
        "documentThree = nlp(\"This is a sentence; This is second sentence; This is last sentence.\")"
      ],
      "metadata": {
        "id": "bAEve85uYMll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now following code will separate the sentences correctly\n",
        "\n",
        "for sentence in documentThree.sents:\n",
        "    print(sentence.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xvKBhjyXwad",
        "outputId": "b0f9218b-9cc3-4387-cad7-f8c8eaeb2014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a sentence;\n",
            "This is second sentence;\n",
            "This is last sentence.\n"
          ]
        }
      ]
    }
  ]
}