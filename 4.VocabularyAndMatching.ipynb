{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Rule-Based Matching"
      ],
      "metadata": {
        "id": "smAf_HFUAk22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "spaCy’s rule-based matcher engines and components not only let you find the words and phrases you’re looking for\n",
        ",they also give you access to the tokens within the document and their relationships\n",
        "\n",
        "This means you can easily access and analyze the surrounding tokens, merge spans into single tokens or add entries to the named entities in doc.ents"
      ],
      "metadata": {
        "id": "5hLfVs2Hv_Le"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWEcqIZHAE9l"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# Import the Matcher library from spacy\n",
        "from spacy.matcher import Matcher"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading en_core_web_sm\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# created matcher object and pass nlp.vocab\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Here matcher is an object that pairs to current Vocab object\n",
        "# We can add and remove specific named matchers to matcher as needed"
      ],
      "metadata": {
        "id": "52nBAh78xqg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating patterns"
      ],
      "metadata": {
        "id": "n61RWdhiztDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a list, and inside that list add series of dictionaries\n",
        "\n",
        "# Hello World can appear in the following ways,\n",
        "\n",
        "# 1) Hello World\n",
        "patternOne = [{\"LOWER\": \"hello\"}, {\"LOWER\": \"world\"}]\n",
        "\n",
        "# 2) Hello-World\n",
        "patternTwo = [{\"LOWER\": \"hello\"}, {\"IS_PUNCT\": True}, {\"LOWER\": \"world\"}]\n",
        "\n",
        "# LOWER, IS_PUNCT are the attributes\n",
        "# they has to be written in  that way only"
      ],
      "metadata": {
        "id": "HDtWS1rnzxsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add patterns to matcher object\n",
        "\n",
        "# Add a match rule to matcher, A match rule consists of,\n",
        "# 1) An ID key\n",
        "# 2) list of patterns\n",
        "matcher.add(\"Hello World\", [patternOne, patternTwo])"
      ],
      "metadata": {
        "id": "zOnbovNzDil6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a document\n",
        "document = nlp(\"Hello World are the first two printed words for most of the programmers, printing Hello-World is most common for beginners\")"
      ],
      "metadata": {
        "id": "UrRf5nmpH3dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## finding the matches"
      ],
      "metadata": {
        "id": "SYM6ydf-ITNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# passing document to matcher object and store this in a variable\n",
        "findMatches = matcher(document)\n",
        "print(findMatches)\n",
        "\n",
        "# it returns output list of tuples\n",
        "# string ID, index start and index end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okWGMGlrIX11",
        "outputId": "ea8be853-b0c1-4783-e1f7-55ac667a5023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(8585552006568828647, 0, 2), (8585552006568828647, 15, 18)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function to find the matches\n",
        "\n",
        "for matchID, start, end in findMatches:\n",
        "    # get string representation\n",
        "    stringID = nlp.vocab.strings[matchID]\n",
        "    # get the matched span\n",
        "    span = document[start:end]\n",
        "    print(matchID, stringID, start, end, span.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COSWCUyfI8FW",
        "outputId": "744ee7fb-8951-4225-ee8a-dae4bcdf175c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8585552006568828647 Hello World 0 2 Hello World\n",
            "8585552006568828647 Hello World 15 18 Hello-World\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing the matches\n",
        "matcher.remove(\"Hello World\")"
      ],
      "metadata": {
        "id": "XoS7YGJVJlCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Redefine the patterns:\n",
        "patternThree = [{\"LOWER\": \"hello\"}, {\"LOWER\": \"world\"}]\n",
        "\n",
        "# \"OP\":\"*\" ----> This is going to allow this pattern to match zero or more times for any punctuation\n",
        "patternFour = [{\"LOWER\": \"hello\"}, {\"IS_PUNCT\": True, \"OP\": \"*\"}, {\"LOWER\": \"world\"}]\n",
        "\n",
        "\n",
        "# Add the new set of patterns to the 'Hellow World' matcher:\n",
        "matcher.add(\"Hello World\", [patternThree, patternFour])"
      ],
      "metadata": {
        "id": "_wnQLXRDJ0lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documentTwo = nlp(\"You can print Hello World or hello world or Hello-World\")"
      ],
      "metadata": {
        "id": "7KdcN5mecwSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "findMatchesTwo = matcher(documentTwo)\n",
        "print(findMatchesTwo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmFRU9ZxdZgC",
        "outputId": "7c223929-c8e1-4a0b-c422-32df2ce7fb1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(8585552006568828647, 3, 5), (8585552006568828647, 6, 8), (8585552006568828647, 9, 12)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function to find the matches\n",
        "\n",
        "for matchID, start, end in findMatchesTwo:\n",
        "    # get string representation\n",
        "    stringID = nlp.vocab.strings[matchID]\n",
        "    # get the matched span\n",
        "    span = documentTwo[start:end]\n",
        "    print(matchID, stringID, start, end, span.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_oRjWjceDMK",
        "outputId": "f08cc957-375a-429c-be04-4f4633ae946d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8585552006568828647 Hello World 3 5 Hello World\n",
            "8585552006568828647 Hello World 6 8 hello world\n",
            "8585552006568828647 Hello World 9 12 Hello-World\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Phrase Matching"
      ],
      "metadata": {
        "id": "-jUaddyNAzo8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above section we used token patterns to perform rule-based matching. An alternative and more efficient method is to match on terminology lists\n",
        "\n",
        "In this case we use PhraseMatcher to create a Doc object from a list of phrases, and pass that into matcher instead"
      ],
      "metadata": {
        "id": "6wUvwv_ih7_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the PhraseMatcher library\n",
        "from spacy.matcher import PhraseMatcher"
      ],
      "metadata": {
        "id": "WlGy47Oxh62F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading PhraseMatcher with nlp.vocab\n",
        "phraseMatcher = PhraseMatcher(nlp.vocab)"
      ],
      "metadata": {
        "id": "3sO8p-pOiGaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# phrase list\n",
        "phraseList = [\"Barack Obama\", \"Angela Merkel\", \"Washington, D.C.\"]"
      ],
      "metadata": {
        "id": "4LADUx-QiiyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert each phrase to a document object\n",
        "# to do that we are using list comprehension\n",
        "# creating list from iterating another list using for in loop\n",
        "phrasePatterns = [nlp(text) for text in phraseList]"
      ],
      "metadata": {
        "id": "bLf9g1SoisTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# phrase objects are not strings\n",
        "phrasePatterns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9K8IpZejHb6",
        "outputId": "a0b15c9d-0a1d-4782-d200-3f3a9a8fc1bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Barack Obama, Angela Merkel, Washington, D.C.]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# they are the spacy docs\n",
        "# thats why they don't have any quotes there like strings\n",
        "type(phrasePatterns[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOru3oQ_kTPR",
        "outputId": "15d395b6-66c6-4d9c-b1c4-0f955c8960de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pass each doc object into the matcher\n",
        "# thats why we have to add asterisk mark before phrasePatterns\n",
        "phraseMatcher.add(\"TerminologyList\", None, *phrasePatterns)"
      ],
      "metadata": {
        "id": "gLOBlppenyxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pursing multiline string through nlp\n",
        "documentThree = nlp(\"German Chancellor Angela Merkel and US President Barack Obama \"\n",
        "          \"converse in the Oval Office inside the White House in Washington, D.C.\")"
      ],
      "metadata": {
        "id": "f0Dkk-f_oTYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# passin doc to matcher object and store this in a variable\n",
        "findPhraseMatches = phraseMatcher(documentThree)\n",
        "print(findPhraseMatches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXMwUC03pNVJ",
        "outputId": "68af1473-ff35-4b43-f933-a12b4182ef6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(3766102292120407359, 2, 4), (3766102292120407359, 7, 9), (3766102292120407359, 19, 22)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function to find the matches\n",
        "\n",
        "for matchID, start, end in findPhraseMatches:\n",
        "    # get string representation\n",
        "    stringID = nlp.vocab.strings[matchID]\n",
        "    # get the matched span\n",
        "    span = documentThree[start:end]\n",
        "    print(matchID, stringID, start, end, span.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYT44gtkpr1Y",
        "outputId": "5a31d597-4a9d-41f0-b656-5b33260da3b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3766102292120407359 TerminologyList 2 4 Angela Merkel\n",
            "3766102292120407359 TerminologyList 7 9 Barack Obama\n",
            "3766102292120407359 TerminologyList 19 22 Washington, D.C.\n"
          ]
        }
      ]
    }
  ]
}