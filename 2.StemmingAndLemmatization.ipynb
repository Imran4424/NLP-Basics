{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Stemming**"
      ],
      "metadata": {
        "id": "H2PK63L7LPJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Playing\n",
        "\n",
        "Play\n",
        "\n",
        "Played\n",
        "\n",
        " => Play"
      ],
      "metadata": {
        "id": "V240ssfOLPLy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ox7HicGvLHSz"
      },
      "outputs": [],
      "source": [
        "words = [\"run\", \"runner\", \"running\", \"ran\", \"runs\", \"easily\", \"fairly\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "jbN9LpyIH5sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer"
      ],
      "metadata": {
        "id": "HCmaOIvOI18d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pStemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "Njmrx_W3J_Bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sStemmer = SnowballStemmer(language=\"english\")"
      ],
      "metadata": {
        "id": "8HYMiibiJ7E4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word + \" ---> \" + pStemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTQw17QGJ7Z4",
        "outputId": "65825afc-34ce-47c8-a76d-5dcded7c743a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run ---> run\n",
            "runner ---> runner\n",
            "running ---> run\n",
            "ran ---> ran\n",
            "runs ---> run\n",
            "easily ---> easili\n",
            "fairly ---> fairli\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# snow ball stemmer is little better than porter stemmer\n",
        "for word in words:\n",
        "  print(word + \" ---> \" + sStemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0T_IApNKxMo",
        "outputId": "e61965ef-3b15-4579-fbec-281fa5ea140b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run ---> run\n",
            "runner ---> runner\n",
            "running ---> run\n",
            "ran ---> ran\n",
            "runs ---> run\n",
            "easily ---> easili\n",
            "fairly ---> fair\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lemmatization**"
      ],
      "metadata": {
        "id": "-_vUfdGcLbwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "YoniY5vKLw6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokensOne = nlp(\"The striped bats are hanging on their feet for best\")"
      ],
      "metadata": {
        "id": "21giqtyIay6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in tokensOne:\n",
        "  print(token.text, \" ----> \", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Izn12adpoBx6",
        "outputId": "7111dd78-dae1-4f92-e51f-4e5ef0b07a77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The  ---->  the\n",
            "striped  ---->  stripe\n",
            "bats  ---->  bat\n",
            "are  ---->  be\n",
            "hanging  ---->  hang\n",
            "on  ---->  on\n",
            "their  ---->  their\n",
            "feet  ---->  foot\n",
            "for  ---->  for\n",
            "best  ---->  good\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = \"The striped bats are hanging on their feet for best\"\n",
        "\n",
        "for word in s1.split():\n",
        "  print(word + \" ---> \" + pStemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsVsYHZDqaGk",
        "outputId": "61aab311-15d9-4876-cf6f-866ca37fa89c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> the\n",
            "striped ---> stripe\n",
            "bats ---> bat\n",
            "are ---> are\n",
            "hanging ---> hang\n",
            "on ---> on\n",
            "their ---> their\n",
            "feet ---> feet\n",
            "for ---> for\n",
            "best ---> best\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Difference between Stemming and Lemmatization\n",
        "\n",
        "Stemming - it is not guaranteed that provided word will be from vocabulary\n",
        "\n",
        "Lemmatization - provided words will be from vocabulary"
      ],
      "metadata": {
        "id": "hICGd2lCrm6c"
      }
    }
  ]
}